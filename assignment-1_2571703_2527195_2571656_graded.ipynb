{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Sheet 1:  Hands-on Linear Regression (deadline: 31 Oct, 14:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this first exercise sheet is to make you familiar with **jupyter notebook** which we will use to run part of the exercises in this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do so you have to implement a very naive algorithm to solve a **linear regression** problem: **Grid Search**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is one of the simplest and also most widely used machine learning algorithms. It is used to model the relationship between a dependent variable $y$ and one or more independent (also called explanatory) variables $x$. Here, we will focus on the case where we just have a single indepenedent variable, so-called **simple linear regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given some inputs $x = \\{x_0, \\dots, x_n\\}$ and corresponding outputs $y = \\{y_0, \\dots, y_n\\}$. Linear regression assumes that there exists an (unknown!) linear relationship between the input and the output, i.e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = f(x) = \\beta_0 + \\beta_1x + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\epsilon$ is an unobserved noise variable. This relationship is approximated as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} = \\hat{f}(x; w_0, w_1) = w_0 + w_1x$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the goal of linear regression is to estimate the unknown parameters $w_0$ and $w_1$ such that the error between the model prediction $\\hat{y}$ and the true output $y$ is minimized. Formaly, let the ith **residual** be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r_i = y_i - \\hat{f}(x_i; w_0, w_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. the difference between the ith output and the ith prediction and let"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$S = \\sum\\limits_{i=1}^n r_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "be the sum of squared residuals. Then one tries to find the paramaters $w_0$ and $w_1$ that minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$MSE = \\frac{1}{n}~S$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the so called **mean squared error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exercise: Fitting a Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will implement several functions which will help you to fit a simple linear regression model on training data using grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before you start:**\n",
    "- Make sure that you use numpy arrays instead of python lists.\n",
    "- You can assume that all vectors are column vectors not row vectors.\n",
    "- Hint: Try to vectorize as much of your computations as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Implement a loss function which measures the average squared difference between the true data and the model prediction, i.e the mean squared error (MSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 1.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will make use of numpy to vectorize most of the computations\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(y, prediction):\n",
    "    \"\"\"\n",
    "    :param y: The true outputs\n",
    "    :param prediction: The predictions of your model\n",
    "    :return: The MSE between the model predictions and the true outputs\n",
    "    \"\"\"\n",
    "    # TODO: implement\n",
    "    N = y.size\n",
    "    # The error in a prediction is always the difference between the predicted output\n",
    "    # and the true output\n",
    "    error = prediction - y\n",
    "    # Now we calculate the Mean Squared Error by taking square of the difference\n",
    "    # and summing up the np array, and averaging this sum\n",
    "    mse = (np.sum(error**2))/N\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points**: 1.0 of 1.0\n",
    "**Comments**:\n",
    "- None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Implement a function which describes a linear relationship between the input and output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_model(intercept, slope, x):\n",
    "    \"\"\"\n",
    "    :param intercept: The model intercept\n",
    "    :param slope: The model slope\n",
    "    :return: The model prediction on x\n",
    "    \"\"\"\n",
    "    # TODO: implement\n",
    "    \n",
    "    # A simple function where we take in the slope and the intercept values and the input data\n",
    "    # to model a simple linear regression model with the formula y = m*x + c\n",
    "    \n",
    "    y = slope * x + intercept\n",
    "    return y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points**: 0.5 of 0.5\n",
    "**Comments**:\n",
    "- None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Given different values for the slope and the intercept of your model. Implement a function which returns those that result in the best fit, i.e. minimizes the difference between the true data and the model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 4.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(intercepts, slopes, x, y):\n",
    "    \"\"\"\n",
    "    :param intercepts: A numpy array of different intercepts\n",
    "    :param slopes: A numpy array of different slopes\n",
    "    :param x: The inputs\n",
    "    :param y: The true outputs\n",
    "    :return (intercept, slope): The intercept and slope that result in the best fit\n",
    "    \"\"\"\n",
    "    # TODO: implement\n",
    "\n",
    "    # Here we will basically go through all the possible (intercept,slope) combinations to find the best model.\n",
    "    # The model parameters that provide with lowest MSE will be returned as (intercept, slope) tuple.\n",
    "    min_err = sys.maxsize\n",
    "    min_index_i = 0\n",
    "    min_index_j = 0\n",
    "    \n",
    "    # Outer loop to loop through the possible intercepts\n",
    "    for i in range(intercepts.size):\n",
    "        # Inner loop to loop through the slopes\n",
    "        for j in range(slopes.size):\n",
    "            # Prediction based on the particular intercept and slope value\n",
    "            pred_out = linear_model(intercepts[i], slopes[j], x)\n",
    "            # Calculate the MSE\n",
    "            mse = loss(y, pred_out)\n",
    "            # If this MSE is less than previously recorded value, simply update the variables\n",
    "            if mse < min_err:\n",
    "                min_err = mse\n",
    "                min_index_i = i\n",
    "                min_index_j = j\n",
    "      \n",
    "    print (\"Minimum MSE obtained by grid search: \",min_err)\n",
    "    \n",
    "    return (intercepts[min_index_i],slopes[min_index_j])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points**: 4.0 of 4.0\n",
    "**Comments**:\n",
    "- None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Fit a linear model over some training data and plot the resulting model using matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 1.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use the datasets functionality provided by sklearn to generate some training data\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "\n",
    "# Let's create some training data to fit our model on\n",
    "x_train, y_train = make_regression(n_samples=50, n_features=1, n_informative=1, noise=30.0)\n",
    "y_train = y_train[:, None] #  make y a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the test data on which we want to evaluate our fitted model\n",
    "\n",
    "x_test = np.linspace(start=-4, stop=4, num=20)\n",
    "x_test = x_test[:, None] #  make x_test a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are the different values for the intercept and slope on which we want to perform a gridsearch\n",
    "intercepts = np.linspace(start=-10.0, stop=10.0, num=50)\n",
    "intercepts = intercepts[:, None] #  make intercepts a column vector\n",
    "slopes = np.linspace(start=0.0, stop=100.0, num=50)\n",
    "slopes = slopes[:, None] #  make slopes a column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write code to fit a linear model on $x_{train}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum MSE obtained by grid search:  937.879922265\n",
      "Slope: [ 75.51020408]\n",
      "Intercept: [-4.28571429]\n"
     ]
    }
   ],
   "source": [
    "# TODO: fit a linear model on x_train\n",
    "# How we fit the model...\n",
    "# We call the function grid_search with the list of possible intercepts, slopes, the training data\n",
    "# This function will build model for each intercept, slope and analyze the MSE and return the best performing model\n",
    "# The return value will be a tuple of (intercept, slope)\n",
    "\n",
    "return_val = grid_search(intercepts, slopes, x_train, y_train)\n",
    "intercept = return_val[0]\n",
    "slope = return_val[1]\n",
    "y_out = linear_model(intercept, slope, x_train)\n",
    "\n",
    "y_test = linear_model(intercept, slope, x_test)\n",
    "\n",
    "#Printing here just for diagnosis\n",
    "print (\"Slope:\",slope)\n",
    "print(\"Intercept:\",intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points**: 1.0 of 1.0\n",
    "**Comments**:\n",
    "- None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test data:  [[-4.        ]\n",
      " [-3.57894737]\n",
      " [-3.15789474]\n",
      " [-2.73684211]\n",
      " [-2.31578947]\n",
      " [-1.89473684]\n",
      " [-1.47368421]\n",
      " [-1.05263158]\n",
      " [-0.63157895]\n",
      " [-0.21052632]\n",
      " [ 0.21052632]\n",
      " [ 0.63157895]\n",
      " [ 1.05263158]\n",
      " [ 1.47368421]\n",
      " [ 1.89473684]\n",
      " [ 2.31578947]\n",
      " [ 2.73684211]\n",
      " [ 3.15789474]\n",
      " [ 3.57894737]\n",
      " [ 4.        ]]\n",
      "predicted y_test data: [[-306.32653061]\n",
      " [-274.53276047]\n",
      " [-242.73899033]\n",
      " [-210.94522019]\n",
      " [-179.15145005]\n",
      " [-147.35767991]\n",
      " [-115.56390977]\n",
      " [ -83.77013963]\n",
      " [ -51.9763695 ]\n",
      " [ -20.18259936]\n",
      " [  11.61117078]\n",
      " [  43.40494092]\n",
      " [  75.19871106]\n",
      " [ 106.9924812 ]\n",
      " [ 138.78625134]\n",
      " [ 170.58002148]\n",
      " [ 202.37379162]\n",
      " [ 234.16756176]\n",
      " [ 265.9613319 ]\n",
      " [ 297.75510204]]\n"
     ]
    }
   ],
   "source": [
    "# Printing the values of x_test and predicted y_test using our linear model\n",
    "\n",
    "print('x_test data: ',x_test)\n",
    "print('predicted y_test data:', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete the code below to plot the training data together with the fitted linear model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngVJKKeD/A/4RPjvUGENbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96178a4128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a matplotlib figure for the training data and our fitted linear regression model\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "axes.scatter(x_train, y_train, color='blue', marker='.', alpha=.6, s=2e2, label='Training Data')\n",
    "axes.scatter(x_test, y_test, color='green', marker='.', alpha=.6, s=2e2, label='Test Data')\n",
    "axes.plot(x_train, y_out, color='red', ls='-', label='Linear Model')\n",
    "axes.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points**: 0.5 of 0.5\n",
    "**Comments**:\n",
    "- It is sufficient to plot the predictions of the model on $x_{test}$. As you can see in your plot $x_{train}$ is a subset of $x_{test}$ anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: Run the code above several times. Each time the generated data will be different. How would you interpret the result? Is the obtained fit good enough? What are disadvantages of the grid search approach and what could be other (better) ways of fitting a linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 3.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. The fit is pretty good if the training data has an underlying linear distribution, but if the data points show too much \n",
    "scatter, the fit doesn't seem to fit the data properly.\n",
    "2. After fitting the model, and predicting the output for the x_test, we can see that the model generated by grid search doesn't accurately fit the data, and a higher order polynomial function might reduce the min-squared error of prediction.\n",
    "3. There are several disadvantages of grid search\n",
    "    a. If we have too many features, our grid will become a very high dimensional matrix grid. This will result in multiple nested loops, slowing down the implementation.\n",
    "    b. Grid search algorithm goes over the parameter space through uniformly spaced points. So, if the step size between two points is not optimal enough, we may miss a better fit that may lie in between two points in the grid.\n",
    "   c. Grid search usually works on a manually set range of parameter values. Often the selection of the parameter range might become difficult. It will be difficult to set the range of parameters if there is more scatter, we have a bigger data-set, and if the underlying data relationship is more complex than just a linear one.\n",
    "4. Some alternative techniques to grid search algorithm could be:\n",
    "\n",
    "    a. One idea is to calculate the derivative of min-squared error with respect to w_j (with j={0,1}; w_0=intercept, w_1=slope)\n",
    "    and set the result to zero. Out of the resulting system of equations, w_0 and w_1 can be calculated directly.\n",
    "    \n",
    "    b. We can use a random sweep of the parameter space instead of an exhaustive grid search technique. Given the same amount\n",
    "    of trials, random search can help us explore more values for each parameter.\n",
    "    \n",
    "    c. Another technique of fitting the model could be to use a technique called gradient descent. Here we initialize our parameters to a certain value, and update the parameter values based on the mean squared error, aiming to minimize the error.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points**: 3.0 of 3.0\n",
    "**Comments**:\n",
    "- very good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading: 10.0 of 10.0 points. Well done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thanks for the detailed comments!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions\n",
    "You should provide a single Jupyter notebook as a solution. The naming should include the assignment number and matriculation IDs of all team members in the following format:\n",
    "**assignment-1_matriculation1_matriculation_2_matriculation3.ipynb** (in case of 3 team members). \n",
    "Make sure to keep the order matriculation1_matriculation_2_matriculation3 the same for all assignments.\n",
    "\n",
    "Please, submit your solution to your tutor (with **[NNIA][assignment-1]** in email subject):\n",
    "1. Maksym Andriushchenko s8mmandr@stud.uni-saarland.de\n",
    "2. Marius Mosbach s9msmosb@stud.uni-saarland.de\n",
    "3. Rajarshi Biswas rbisw17@gmail.com\n",
    "\n",
    "**If you are in a team, please submit only 1 solution to only 1 tutor.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
